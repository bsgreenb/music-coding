{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musical Sound\n",
    "\n",
    "Sources for this and other chapters are Music Theory for Computer Musicians 1st Edition\n",
    "by Michael Hewitt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies if needed\n",
    "%pip install matplotlib numpy ipywidgets --quiet\n",
    "\n",
    "# Auto-reload lib modules when they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music vs Noise\n",
    "\n",
    "The sounds we hear in music result from a vibratory disturbance of the atmosphere and objects\n",
    "in the environment around us—sound waves, in other words. When those sound waves are chaotic, jumbled, and confused, we call the result a noise. The pleasure we get from noise is limited.\n",
    "\n",
    "However, some sound sources—particularly musical instruments—produce regular, ordered,\n",
    "and patterned sound waves. These sound sources create music, rather than just noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sound Waves\n",
    "\n",
    "### Physics of Waves\n",
    "\n",
    "Physically, a **wave** is a bounded, piecewise-continuous disturbance propagating through space and time that transfers energy without permanently displacing the medium. When multiple waves occur simultaneously, they combine through **superposition**—their displacements add algebraically at each point in space and time to form a single combined wave.\n",
    "\n",
    "Variables:\n",
    "- $x$: Position (m)\n",
    "- $y$: Displacement (Pa — Pascals = N/m², the SI unit of pressure)\n",
    "- $t$: Time (s)\n",
    "- $A$: Amplitude (Pa — maximum displacement from equilibrium)\n",
    "- $f$: Frequency (Hz, cycles per second — perceived as pitch)\n",
    "- $\\omega$: Angular Frequency (rad/s. Defined as $\\omega = 2\\pi f$)\n",
    "- $\\lambda$: Wavelength (m/cycle)\n",
    "- $k$: Angular Wavenumber (rad/m. Defined as $k = \\frac{2\\pi}{\\lambda}$)\n",
    "- $c$: Speed of Sound (m/s)\n",
    "\n",
    "The speed of sound ($c$) implies that Frequency and Wavelength are inversely proportional. It strictly locks the time components ($f, \\omega$) and space components ($\\lambda, k$) together:\n",
    "$$c = f \\lambda = \\frac{\\omega}{k}$$\n",
    "\n",
    "**Physical Wave Equation (Space & Time)**:\n",
    "\n",
    "$$y(x, t) = A \\sin(kx - \\omega t)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Waves in Music\n",
    "\n",
    "In music creation, this definition is relaxed to a function of time alone (a signal), abstracting away spatial propagation while retaining the requirements of boundedness and equilibrium.\n",
    "\n",
    "**Signal Equation (Time only, fixed at $x=0$)**: By substituting $\\omega = 2\\pi f$, we get the standard form used in Digital Signal Processing:\n",
    "\n",
    "$$y(t) = A \\sin(2\\pi f t)$$\n",
    "\n",
    "#### Pitch (Frequency)\n",
    "\n",
    "The range in frequency of an instrument is referred to as its **characteristic register**.  \n",
    "\n",
    "#### Amplitude and Decibels\n",
    "\n",
    "In the physical wave equation, amplitude is measured in Pascals (Pa) — the SI unit of pressure. However, in music production and digital audio, we treat amplitude as a **scalar from -1 to 1**. This abstraction exists because the actual sound pressure that reaches your ears depends entirely on your playback equipment. The audio file simply encodes *relative* levels, and the hardware translates these into real-world pressures.\n",
    "\n",
    "The volume or amplitude of each note (or beat, in the case of drums) is called the **velocity**, which is a scalar from 0 to 127.  \n",
    "\n",
    "**dBFS** is a logarithmic measure of a digital signal's amplitude relative to the maximum level the system can encode before distortion occurs. This unit is standard in digital audio workstations (DAWs) and CD mastering, where $0 \\text{ dBFS}$ represents the absolute ceiling and valid signals are typically negative values.\n",
    "\n",
    "$$L_{dBFS} = 20 \\log_{10}\\left(\\frac{A}{A_{max}}\\right)$$\n",
    "\n",
    "- $L_{dBFS}$: Digital Level (Unit: decibels)\n",
    "- $A$: Current signal amplitude (Unit: Sample Value, e.g., a 16-bit integer)\n",
    "- $A_{max}$: Maximum possible amplitude (Unit: Sample Value, e.g., 32,767 for 16-bit audio)\n",
    "\n",
    "Note: dB SPL is what's used in n acoustics and environmental noise monitoring, and has its own conversion.  But we're not worried about that in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Rate\n",
    "\n",
    "Sample rate defines the \"resolution\" of time for digital music.\n",
    "\n",
    "Just as a movie is a sequence of still photos (frames) displayed quickly to create the illusion of motion, digital audio is a series of \"snapshots\" (samples) of a sound wave. The **Sample Rate** is simply the count of these snapshots taken in one second, measured in **Hertz (Hz)** (which is itself cycles per second).\n",
    "\n",
    "[Nyquist-Shannon Sampling Theorem](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem) says that to digitally capture a specific frequency, you must capture at least two samples per cycle of that wave. This defines the **Nyquist Frequency** ($f_{Nyquist} = f_s / 2$) as the highest pitch you can record for a given sample rate ($f_s$). Since human hearing ranges up to ~20,000 Hz, we need a sample rate of at least 40,000 Hz to capture everything we can hear.\n",
    "\n",
    "**44.1 kHz** is the standard for CDs and consumer music. It was chosen to be slightly above the 40 kHz requirement to allow for a safety margin for audio filters. **48 kHz** is the standard for video, while higher rates like **96 kHz** are used in professional studios for processing flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive Tone Visualization\n",
    "\n",
    "Adjust the sliders below to see how frequency, amplitude, and duration affect the waveform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28675077e2f4fe4b0b317d704314119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=440.0, continuous_update=False, description='Frequency (Hz):', layout=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider\n",
    "from lib.plots import create_line_chart\n",
    "\n",
    "# Constants\n",
    "SAMPLE_RATE = 44100  # Standard for CD-quality audio\n",
    "MS_PER_SECOND = 1000\n",
    "\n",
    "@interact(\n",
    "    frequency=FloatSlider(value=440, min=20, max=2000, step=10, description='Frequency (Hz):',\n",
    "                          style={'description_width': '120px'}, layout={'width': '400px'}, continuous_update=False),\n",
    "    amplitude=FloatSlider(value=1.0, min=0.0, max=1.0, step=0.05, description='Amplitude:',\n",
    "                          style={'description_width': '120px'}, layout={'width': '400px'}, continuous_update=False),\n",
    "    duration_ms=FloatSlider(value=50, min=10, max=200, step=10, description='Duration (ms):',\n",
    "                            style={'description_width': '120px'}, layout={'width': '400px'}, continuous_update=False),\n",
    ")\n",
    "def plot_sine_wave(frequency: float, amplitude: float, duration_ms: float) -> None:\n",
    "    \"\"\"Plot a sine wave with the given frequency, amplitude, and duration.\"\"\"\n",
    "    plt.close('all')\n",
    "    \n",
    "    duration_seconds = duration_ms / MS_PER_SECOND\n",
    "    t = np.linspace(0, duration_seconds, int(SAMPLE_RATE * duration_seconds))\n",
    "    y = amplitude * np.sin(2 * np.pi * frequency * t)\n",
    "    \n",
    "    create_line_chart(\n",
    "        x=t * MS_PER_SECOND,\n",
    "        y=y,\n",
    "        xlabel='Time (ms)',\n",
    "        ylabel='Amplitude',\n",
    "        title=f'y(t) = {amplitude:.1f} \\u00b7 sin(2\\u03c0 \\u00b7 {frequency:.0f} \\u00b7 t)',\n",
    "        ylim=(-1.1, 1.1)\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timbre\n",
    "\n",
    "**Timbre**, aka tone quality or tone color, is the property that enables the ear to distinguish between the sound of different instruments.\n",
    "\n",
    "Each musical tone that you hear is a combination of lots of pure tones. Mathematically, we represent this as a sum of harmonic sinusoids:\n",
    "\n",
    "$$y(t) = \\sum_{n=1}^{N} A_n \\sin(2\\pi n f_0 t + \\phi_n)$$\n",
    "\n",
    "Where:\n",
    "- $f_0$: Fundamental frequency (Hz)\n",
    "- $n$: Harmonic number (1 = fundamental, 2 = second harmonic, etc.)\n",
    "- $A_n$: Amplitude of the $n$ th harmonic\n",
    "- $\\phi_n$: Phase offset of the $n$ th harmonic (rad)\n",
    "- $N$: Number of harmonics (theoretically infinite)\n",
    "\n",
    "For example, a guitar string does not just vibrate along its whole length. It also vibrates along the regular fractional lengths of the string, which are the various halves, thirds, quarters, fifths, and so on from which the string as a whole is comprised. These fractional lengths are called **modes of vibration**, and each mode of vibration produces its own characteristic frequency.\n",
    "\n",
    "**Table: Harmonic Series — The First Eight Harmonics of A**\n",
    "\n",
    "| Harmonic | Note | Frequency | Ratio |\n",
    "|----------|------|-----------|-------|\n",
    "| 1st (Fundamental) | A1 | 110 Hz | 1 |\n",
    "| 2nd | A2 | 220 Hz | 2 |\n",
    "| 3rd | E3 | 330 Hz | 3 |\n",
    "| 4th | A3 | 440 Hz | 4 |\n",
    "| 5th | C♯4 | 550 Hz | 5 |\n",
    "| 6th | E4 | 660 Hz | 6 |\n",
    "| 7th | F♯4† | 770 Hz | 7 |\n",
    "| 8th | A4 | 880 Hz | 8 |\n",
    "\n",
    "*† The 7th harmonic falls between F♯ and G, so it's slightly flat compared to equal temperament.*\n",
    "\n",
    "The first mode of vibration is called the **fundamental frequency** aka the first partial or first harmonic. The fundamental frequency is of vital importance because it determines the pitch of the note that we hear. The second mode is the second partial, and the third the third partial, and so on. This theoretically extends to infinity.\n",
    "\n",
    "Most musical instruments produce musical tones that are rich in such partials. Partials whose frequencies represent whole-number multiples of the fundamental frequency are called **harmonics**. A succession of such partials—such as 100 Hz, 200 Hz, 300 Hz, 400 Hz, 500 Hz, and so on—is called a **harmonic series**. Most of the instruments we are familiar with produce harmonic partials. This is due to the characteristic nature of the vibrating mechanisms that produce the tone. \n",
    "\n",
    "The spectrum of harmonic partials that can be present within a given tone is theoretically infinite.\n",
    "\n",
    "Some instruments, such as gongs, bells, and other percussion instruments, produce partials that are not whole-number multiples of the frequency of the fundamental. These are called **inharmonic partials**, and they give rise to sounds of more indefinite pitch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesis\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
